{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MEng Computer Science Thesis Implementation"
      ],
      "metadata": {
        "id": "aT16Td1MIT3V"
      },
      "id": "aT16Td1MIT3V"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Title:** Benchmarking Persian Instruction-Tuned LLMs Versus State-of-the-Art NLP Models for Sentiment Analysis <br/>\n",
        "**Student Name:** Seyyed Jalal Tabatabaee <br/>\n",
        "**Student ID:** GH1033801 <br/>\n",
        "**Supervisor:** Prof. Dr. Reza Babaei <br/>\n",
        "**Semester:** Summer 2025 <br/>\n",
        "**University:** Gisma University of Applied Sciences <br/>\n",
        "**Github Link:** https://github.com/shayantabatabaee/llm-sentiment-analysis <br/>\n",
        "**Dataset Link:** https://github.com/persiannlp/parsinlu\n",
        "\n"
      ],
      "metadata": {
        "id": "XFL1Y7LyIpoS"
      },
      "id": "XFL1Y7LyIpoS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction"
      ],
      "metadata": {
        "id": "mMeYL647MjUI"
      },
      "id": "mMeYL647MjUI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focuses on sentiment analysis for the Persian language, a low-resource language that has been underexplored in modern NLP research. While most sentiment analysis studies have been conducted in English, Persian poses unique challenges due to its complex grammar, diverse vocabulary, and the absence of diacritics.\n",
        "\n",
        "Traditional approaches to sentiment analysis involve steps like text preprocessing, embedding generation, and classification using machine learning (ML) or deep learning (DL) models. However, with the emergence of large language models (LLMs) such as ChatGPT, new techniques like zero-shot and few-shot prompting have shown promising results — even without fine-tuning.\n",
        "\n",
        "This research benchmarks instruction-tuned Persian LLMs (with fewer parameters) on the ParsiNLU sentiment dataset and compares their performance against state-of-the-art traditional models like BERT. The goal is to investigate whether smaller, Persian-specific LLMs can offer performance comparable to larger multilingual models while being more cost-efficient and practical for real-world applications.\n",
        "\n"
      ],
      "metadata": {
        "id": "tn7uw8z0Mn26"
      },
      "id": "tn7uw8z0Mn26"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Libraries"
      ],
      "metadata": {
        "id": "TtxvszToM1ob"
      },
      "id": "TtxvszToM1ob"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets\n",
        "!pip install -q pandas"
      ],
      "metadata": {
        "id": "Nwd50n3RMpI2"
      },
      "id": "Nwd50n3RMpI2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "MqTYfjNhNrFH"
      },
      "id": "MqTYfjNhNrFH"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from IPython.display import display\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "kjCE-NESNYwp"
      },
      "id": "kjCE-NESNYwp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Variables"
      ],
      "metadata": {
        "id": "TiQpdjLNS2kO"
      },
      "id": "TiQpdjLNS2kO"
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_URL = \"https://raw.githubusercontent.com/persiannlp/parsinlu/master/data/sentiment-analysis/food.jsonl\"\n",
        "LABEL_MAP = {\n",
        "    \"3\": \"OTHER\",\n",
        "    \"2\": \"POSITIVE\",\n",
        "    \"1\": \"POSITIVE\",\n",
        "    \"0\": \"NEUTRAL\",\n",
        "    \"-1\": \"NEGATIVE\",\n",
        "    \"-2\": \"NEGATIVE\"\n",
        "}\n",
        "TEST_COUNT = 190\n",
        "RANDOM_STATE = 18"
      ],
      "metadata": {
        "id": "41E5HYEGS751"
      },
      "id": "41E5HYEGS751",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_en_fa = {\n",
        "    \"OTHER\": \"سایر\",\n",
        "    \"POSITIVE\": \"مثبت\",\n",
        "    \"NEUTRAL\": \"خنثی\",\n",
        "    \"NEGATIVE\": \"منفی\"\n",
        "}"
      ],
      "metadata": {
        "id": "7M0zcXzwg7tm"
      },
      "id": "7M0zcXzwg7tm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preprocessing"
      ],
      "metadata": {
        "id": "03uecM7sOaxr"
      },
      "id": "03uecM7sOaxr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure a direct comparison with the baseline study [(Abaskohi et al., 2024)](https://arxiv.org/pdf/2404.02403), we used the same dataset and fixed the random seed. Additionally, we merged the original six sentiment categories into four, matching the label structure used in the baseline. The original dataset contains six labels: *VERY_POSITIVE, POSITIVE, NEUTRAL, NEGATIVE, VERY_NEGATIVE,* and *OTHER*. For our analysis, we merged *VERY_POSITIVE* with *POSITIVE* and *VERY_NEGATIVE* with *NEGATIVE*."
      ],
      "metadata": {
        "id": "LtUCtvETYmq-"
      },
      "id": "LtUCtvETYmq-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset"
      ],
      "metadata": {
        "id": "C0cZTb3SYgF_"
      },
      "id": "C0cZTb3SYgF_"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"json\", data_files=DATASET_URL)\n",
        "df = dataset['train'].to_pandas()\n",
        "df = df[['review', 'sentiment']]\n",
        "df['sentiment'] = df['sentiment'].map(LABEL_MAP)"
      ],
      "metadata": {
        "id": "4d-qNn9FOkTa"
      },
      "id": "4d-qNn9FOkTa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df = df.sample(n=TEST_COUNT, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "SrLr_OtNgkol"
      },
      "id": "SrLr_OtNgkol",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Dataset"
      ],
      "metadata": {
        "id": "nv_62kpadn71"
      },
      "id": "nv_62kpadn71"
    },
    {
      "cell_type": "code",
      "source": [
        "def insight(data):\n",
        "  print(f\"Dataset shape: {data.shape}\", end=\"\\n\\n\")\n",
        "  print(\"Five sample of data\")\n",
        "  display(data.head(5))\n",
        "  print(\"\\n\\nDataset info\", end=\"\\n\\n\")\n",
        "  display(data['sentiment'].value_counts())\n",
        "  data['sentiment'].value_counts().plot.bar(x=\"Sentiment\", y=\"Count\", rot=45)"
      ],
      "metadata": {
        "id": "KTJnCoKXXUaI"
      },
      "id": "KTJnCoKXXUaI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insight(df)"
      ],
      "metadata": {
        "id": "vPGDO_M5fG0_"
      },
      "id": "vPGDO_M5fG0_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insight(sub_df)"
      ],
      "metadata": {
        "id": "SKrk0hi4eHzT"
      },
      "id": "SKrk0hi4eHzT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts"
      ],
      "metadata": {
        "id": "1ap-MKdmIEaj"
      },
      "id": "1ap-MKdmIEaj"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_message(prompt):\n",
        "  return [{\"role\": \"system\", \"content\": prompt[0]},{\"role\": \"user\", \"content\": prompt[1]}]"
      ],
      "metadata": {
        "id": "rTrsIbzhQ2aK"
      },
      "id": "rTrsIbzhQ2aK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### System Prompts"
      ],
      "metadata": {
        "id": "JXW7wIp5LD0v"
      },
      "id": "JXW7wIp5LD0v"
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_01 = \"\"\"\n",
        "تو یک دستار هوشمند برای تشخیص احساسات از متن داده شده هستی. \\\n",
        "با توجه به متن داده شده فقط این خروجی ها ممکن ست : خنثی، مثبت، منفی، سایر. \\\n",
        "در صورتی که نتوانستی به درستی احساسات را تحلیل کنی فقط خروجی سایر را برگردان.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "G63BOFJiLJTH"
      },
      "id": "G63BOFJiLJTH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_02 = \"\"\"\n",
        "You are an AI asistant for sentiment analysis. \\\n",
        "According to given text only these outputs are possible: NEUTRAL, POSITIVE, NEGATIVE, OTHER. \\\n",
        "If you can not detect the sentiment correctly only return OTHER.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "a_ZJuoAxM7jV"
      },
      "id": "a_ZJuoAxM7jV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero-Shot User Prompts"
      ],
      "metadata": {
        "id": "MrDTOlt4NjvS"
      },
      "id": "MrDTOlt4NjvS"
    },
    {
      "cell_type": "code",
      "source": [
        "zs_user_prompt_01= \"\"\"\n",
        "نظر: REVIEW,\n",
        "احساس:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "a5FHkTatNhAu"
      },
      "id": "a5FHkTatNhAu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zs_user_prompt_02=\"\"\"\n",
        "Review: REVIEW,\n",
        "Sentiment:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hhJhoTg-OFaY"
      },
      "id": "hhJhoTg-OFaY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-Shot User Prompts"
      ],
      "metadata": {
        "id": "KcCox2-hSz9K"
      },
      "id": "KcCox2-hSz9K"
    },
    {
      "cell_type": "code",
      "source": [
        "diff_df = df.loc[~df.index.isin(sub_df.index)]\n",
        "def create_examples_df(df, n_samples):\n",
        "    groups = df['sentiment'].unique()\n",
        "    sampled = []\n",
        "\n",
        "    for sentiment in groups:\n",
        "        group_df = df[df['sentiment'] == sentiment]\n",
        "        sampled_df = group_df.sample(n=n_samples, random_state=RANDOM_STATE)\n",
        "        sampled.append(sampled_df)\n",
        "\n",
        "    return pd.concat(sampled).sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "FDqt3DbtTde_"
      },
      "id": "FDqt3DbtTde_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_example_prompts():\n",
        "  examples_df = create_examples_df(diff_df, 1)\n",
        "  en_examples = \"\"\n",
        "  fa_examples = \"\"\n",
        "  for i, row in examples_df.iterrows():\n",
        "    en_examples += f\"Example {i+1}:\\n\"\n",
        "    en_examples += f\"Review: {row['review']}\\n\"\n",
        "    en_examples += f\"Sentiment: {row['sentiment']}\\n\"\n",
        "\n",
        "    fa_examples += f\"مثال {i+1}:\\n\"\n",
        "    fa_examples += f\"نظر: {row['review']}\\n\"\n",
        "    fa_examples += f\"احساس: {label_en_fa[row['sentiment']]}\\n\"\n",
        "\n",
        "  return en_examples, fa_examples"
      ],
      "metadata": {
        "id": "K4nzoexQfnCr"
      },
      "id": "K4nzoexQfnCr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_examples, fa_examples = create_example_prompts()\n",
        "print(en_examples)\n",
        "print(\"*\" * 50)\n",
        "print(fa_examples)"
      ],
      "metadata": {
        "id": "tlvaH3mzhPU7"
      },
      "id": "tlvaH3mzhPU7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs_user_promps_01 = f\"\"\"\n",
        "مثالها: \\\n",
        "{fa_examples}\n",
        "\n",
        "نظر: REVIEW,\n",
        "احساس:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "p2YRuI69b_dI"
      },
      "id": "p2YRuI69b_dI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs_user_promps_02 = f\"\"\"\n",
        "Examples: \\\n",
        "{en_examples}\n",
        "\n",
        "Review: REVIEW,\n",
        "Sentiment:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qoHeHPFPcC3Y"
      },
      "id": "qoHeHPFPcC3Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Prompts"
      ],
      "metadata": {
        "id": "W8QqAYKdOqks"
      },
      "id": "W8QqAYKdOqks"
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_combination = [(system_prompt_01, zs_user_prompt_01), (system_prompt_02, zs_user_prompt_02)]\n",
        "few_shot_combination = [(system_prompt_01, fs_user_promps_01), (system_prompt_02, fs_user_promps_02)]\n",
        "zero_shot_final_promps = [get_message(prompt) for prompt in zero_shot_combination]\n",
        "few_shot_final_promps = [get_message(prompt) for prompt in few_shot_combination]"
      ],
      "metadata": {
        "id": "mjj7u1MaON3c"
      },
      "id": "mjj7u1MaON3c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}