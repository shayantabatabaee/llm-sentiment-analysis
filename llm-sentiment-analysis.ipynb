{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"aT16Td1MIT3V","cell_type":"markdown","source":"# MEng Computer Science Thesis Implementation","metadata":{"id":"aT16Td1MIT3V"}},{"id":"XFL1Y7LyIpoS","cell_type":"markdown","source":"**Title:** Benchmarking Persian Instruction-Tuned LLMs Versus State-of-the-Art NLP Models for Sentiment Analysis <br/>\n**Student Name:** Seyyed Jalal Tabatabaee <br/>\n**Student ID:** GH1033801 <br/>\n**Supervisor:** Prof. Dr. Reza Babaei <br/>\n**Semester:** Summer 2025 <br/>\n**University:** Gisma University of Applied Sciences <br/>\n**Github Link:** https://github.com/shayantabatabaee/llm-sentiment-analysis <br/>\n**Dataset Link:** https://github.com/persiannlp/parsinlu\n\n","metadata":{"id":"XFL1Y7LyIpoS"}},{"id":"mMeYL647MjUI","cell_type":"markdown","source":"### Introduction","metadata":{"id":"mMeYL647MjUI"}},{"id":"tn7uw8z0Mn26","cell_type":"markdown","source":"This project focuses on sentiment analysis for the Persian language, a low-resource language that has been underexplored in modern NLP research. While most sentiment analysis studies have been conducted in English, Persian poses unique challenges due to its complex grammar, diverse vocabulary, and the absence of diacritics.\n\nTraditional approaches to sentiment analysis involve steps like text preprocessing, embedding generation, and classification using machine learning (ML) or deep learning (DL) models. However, with the emergence of large language models (LLMs) such as ChatGPT, new techniques like zero-shot and few-shot prompting have shown promising results — even without fine-tuning.\n\nThis research benchmarks instruction-tuned Persian LLMs (with fewer parameters) on the ParsiNLU sentiment dataset and compares their performance against state-of-the-art traditional models like BERT. The goal is to investigate whether smaller, Persian-specific LLMs can offer performance comparable to larger multilingual models while being more cost-efficient and practical for real-world applications.\n\n","metadata":{"id":"tn7uw8z0Mn26"}},{"id":"TtxvszToM1ob","cell_type":"markdown","source":"### Install Libraries","metadata":{"id":"TtxvszToM1ob"}},{"id":"Nwd50n3RMpI2","cell_type":"code","source":"!pip install -q datasets\n!pip install -q pandas\n!pip install -q torch\n!pip install -q transformers\n!pip install -U -q accelerate\n!pip install -q tqdm\n!pip install -q scikit-learn\n!pip install -q seaborn","metadata":{"id":"Nwd50n3RMpI2","trusted":true},"outputs":[],"execution_count":null},{"id":"MqTYfjNhNrFH","cell_type":"markdown","source":"### Import Libraries","metadata":{"id":"MqTYfjNhNrFH"}},{"id":"cf179213-c445-4aff-a6ec-f22935bd68de","cell_type":"code","source":"import os\n\nos.environ[\"FORCE_TF_AVAILABLE\"] = \"0\"\nos.environ[\"USE_TF\"]=\"0\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"kjCE-NESNYwp","cell_type":"code","source":"import re\nimport copy\nimport torch\nimport transformers\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom datasets import load_dataset\nfrom IPython.display import display, display_html\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, LlamaTokenizer, LlamaForCausalLM\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"id":"kjCE-NESNYwp","trusted":true},"outputs":[],"execution_count":null},{"id":"TiQpdjLNS2kO","cell_type":"markdown","source":"### Initialize Variables","metadata":{"id":"TiQpdjLNS2kO"}},{"id":"41E5HYEGS751","cell_type":"code","source":"DATASET_URL = \"https://raw.githubusercontent.com/persiannlp/parsinlu/master/data/sentiment-analysis/food.jsonl\"\nLABEL_MAP = {\n    \"3\": \"OTHER\",\n    \"2\": \"POSITIVE\",\n    \"1\": \"POSITIVE\",\n    \"0\": \"NEUTRAL\",\n    \"-1\": \"NEGATIVE\",\n    \"-2\": \"NEGATIVE\"\n}\nTEST_COUNT = 190\nRANDOM_STATE = 18\nos.environ['HF_TOKEN'] = \"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\"","metadata":{"id":"41E5HYEGS751","trusted":true},"outputs":[],"execution_count":null},{"id":"7M0zcXzwg7tm","cell_type":"code","source":"label_en_fa = {\n    \"OTHER\": \"سایر\",\n    \"POSITIVE\": \"مثبت\",\n    \"NEUTRAL\": \"خنثی\",\n    \"NEGATIVE\": \"منفی\"\n}\nlabel_fa_en = {v:k for k,v in label_en_fa.items()}","metadata":{"id":"7M0zcXzwg7tm","trusted":true},"outputs":[],"execution_count":null},{"id":"03uecM7sOaxr","cell_type":"markdown","source":"## Dataset Preprocessing","metadata":{"id":"03uecM7sOaxr"}},{"id":"LtUCtvETYmq-","cell_type":"markdown","source":"To ensure a direct comparison with the baseline study [(Abaskohi et al., 2024)](https://arxiv.org/pdf/2404.02403), we used the same dataset and fixed the random seed. Additionally, we merged the original six sentiment categories into four, matching the label structure used in the baseline. The original dataset contains six labels: *VERY_POSITIVE, POSITIVE, NEUTRAL, NEGATIVE, VERY_NEGATIVE,* and *OTHER*. For our analysis, we merged *VERY_POSITIVE* with *POSITIVE* and *VERY_NEGATIVE* with *NEGATIVE*.","metadata":{"id":"LtUCtvETYmq-"}},{"id":"C0cZTb3SYgF_","cell_type":"markdown","source":"### Load Dataset","metadata":{"id":"C0cZTb3SYgF_"}},{"id":"4d-qNn9FOkTa","cell_type":"code","source":"dataset = load_dataset(\"json\", data_files=DATASET_URL)\ndf = dataset['train'].to_pandas()\ndf = df[['review', 'sentiment']]\ndf['sentiment'] = df['sentiment'].map(LABEL_MAP)","metadata":{"id":"4d-qNn9FOkTa","trusted":true},"outputs":[],"execution_count":null},{"id":"SrLr_OtNgkol","cell_type":"code","source":"sub_df = df.sample(n=TEST_COUNT, random_state=RANDOM_STATE)","metadata":{"id":"SrLr_OtNgkol","trusted":true},"outputs":[],"execution_count":null},{"id":"nv_62kpadn71","cell_type":"markdown","source":"### Visualize Dataset","metadata":{"id":"nv_62kpadn71"}},{"id":"KTJnCoKXXUaI","cell_type":"code","source":"def insight(data):\n  print(f\"Dataset shape: {data.shape}\", end=\"\\n\\n\")\n  print(\"Five sample of data\")\n  display(data.head(5))\n  print(\"\\n\\nDataset info\", end=\"\\n\\n\")\n  display(data['sentiment'].value_counts())\n  data['sentiment'].value_counts().plot.bar(x=\"Sentiment\", y=\"Count\", rot=45)","metadata":{"id":"KTJnCoKXXUaI","trusted":true},"outputs":[],"execution_count":null},{"id":"vPGDO_M5fG0_","cell_type":"code","source":"insight(df)","metadata":{"id":"vPGDO_M5fG0_","trusted":true},"outputs":[],"execution_count":null},{"id":"SKrk0hi4eHzT","cell_type":"code","source":"insight(sub_df)","metadata":{"id":"SKrk0hi4eHzT","trusted":true},"outputs":[],"execution_count":null},{"id":"1ap-MKdmIEaj","cell_type":"markdown","source":"## Prompts","metadata":{"id":"1ap-MKdmIEaj"}},{"id":"rTrsIbzhQ2aK","cell_type":"code","source":"def get_message(prompt):\n  return [{\"role\": \"system\", \"content\": prompt[0]},{\"role\": \"user\", \"content\": prompt[1]}]","metadata":{"id":"rTrsIbzhQ2aK","trusted":true},"outputs":[],"execution_count":null},{"id":"JXW7wIp5LD0v","cell_type":"markdown","source":"### System Prompts","metadata":{"id":"JXW7wIp5LD0v"}},{"id":"G63BOFJiLJTH","cell_type":"code","source":"system_prompt_01 = \"\"\"\nتو یک دستیار هوشمند برای تحلیل احساسات هستی.\nیک نظر کوتاه درباره ی غذا به زبان فارسی دریافت میکنی.\nوظیفه‌ی تو این است که احساس کلی نظر را در یکی از چهار دسته‌ی زیر طبقه‌بندی کنی:\n\n- مثبت\n- منفی\n- خنثی\n- سایر\n\nفقط یکی از این چهار برچسب را برگردان. هیچ متن اضافی، توضیح، یا عبارتی مانند «احساس:» در پاسخ ننویس.\nاگر احساس نظر نامشخص، متناقض یا ترکیبی بود، فقط برچسب «سایر» را برگردان\nاگر حس متن مثبت یا منفی نبود خنثی را برگردان\n\"\"\"","metadata":{"id":"G63BOFJiLJTH","trusted":true},"outputs":[],"execution_count":null},{"id":"a_ZJuoAxM7jV","cell_type":"code","source":"system_prompt_02 = \"\"\"\nYou are an AI assistant for sentiment analysis. \nYou will receive a short user opinion about food, written in Persian. \nYour task is to classify the overall sentiment of the opinion as one of the following four categories:\n\n- POSITIVE\n- NEGATIVE\n- NEUTRAL\n- OTHER\n\nReturn ONLY one of the four labels listed above. Do not include any additional text, explanations, or prefixes such as 'Sentiment:'. \nIf the sentiment is unclear, contradictory, or mixed, return OTHER.\nIf the sentiment is not POSITIVE or NEGATIVE return NEUTRAL.\n\"\"\"","metadata":{"id":"a_ZJuoAxM7jV","trusted":true},"outputs":[],"execution_count":null},{"id":"MrDTOlt4NjvS","cell_type":"markdown","source":"### Zero-Shot User Prompts","metadata":{"id":"MrDTOlt4NjvS"}},{"id":"a5FHkTatNhAu","cell_type":"code","source":"zs_user_prompt_01= \"\"\"\nنظر: REVIEW\nاحساس (مثبت، منفی، خنثی، سایر):\n\"\"\"","metadata":{"id":"a5FHkTatNhAu","trusted":true},"outputs":[],"execution_count":null},{"id":"hhJhoTg-OFaY","cell_type":"code","source":"zs_user_prompt_02=\"\"\"\nReview: REVIEW\nSentiment (POSITIVE, NEGATIVE, NEUTRAL, OTHER):\n\"\"\"","metadata":{"id":"hhJhoTg-OFaY","trusted":true},"outputs":[],"execution_count":null},{"id":"KcCox2-hSz9K","cell_type":"markdown","source":"### Few-Shot User Prompts","metadata":{"id":"KcCox2-hSz9K"}},{"id":"FDqt3DbtTde_","cell_type":"code","source":"diff_df = df.loc[~df.index.isin(sub_df.index)]\ndef create_examples_df(df, n_samples):\n    groups = df['sentiment'].unique()\n    sampled = []\n\n    for sentiment in groups:\n        group_df = df[df['sentiment'] == sentiment]\n        sampled_df = group_df.sample(n=n_samples, random_state=RANDOM_STATE)\n        sampled.append(sampled_df)\n\n    return pd.concat(sampled).sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)","metadata":{"id":"FDqt3DbtTde_","trusted":true},"outputs":[],"execution_count":null},{"id":"K4nzoexQfnCr","cell_type":"code","source":"def create_example_prompts():\n  examples_df = create_examples_df(diff_df, 1)\n  en_examples = \"\"\n  fa_examples = \"\"\n  for i, row in examples_df.iterrows():\n    en_examples += f\"Example {i+1}:\\n\"\n    en_examples += f\"Review: {row['review']}\\n\"\n    en_examples += f\"Sentiment: {row['sentiment']}\\n\"\n\n    fa_examples += f\"مثال {i+1}:\\n\"\n    fa_examples += f\"نظر: {row['review']}\\n\"\n    fa_examples += f\"احساس: {label_en_fa[row['sentiment']]}\\n\"\n\n  return en_examples, fa_examples","metadata":{"id":"K4nzoexQfnCr","trusted":true},"outputs":[],"execution_count":null},{"id":"tlvaH3mzhPU7","cell_type":"code","source":"en_examples, fa_examples = create_example_prompts()\nprint(en_examples)\nprint(\"*\" * 50)\nprint(fa_examples)","metadata":{"id":"tlvaH3mzhPU7","trusted":true},"outputs":[],"execution_count":null},{"id":"p2YRuI69b_dI","cell_type":"code","source":"fs_user_promps_01 = f\"\"\"\nمثالها:\n{fa_examples}\n\nنظر: REVIEW\nاحساس (مثبت، منفی، خنثی، سایر):\n\"\"\"","metadata":{"id":"p2YRuI69b_dI","trusted":true},"outputs":[],"execution_count":null},{"id":"qoHeHPFPcC3Y","cell_type":"code","source":"fs_user_promps_02 = f\"\"\"\nExamples:\n{en_examples}\n\nReview: REVIEW\nSentiment (POSITIVE, NEGATIVE, NEUTRAL, OTHER):\n\"\"\"","metadata":{"id":"qoHeHPFPcC3Y","trusted":true},"outputs":[],"execution_count":null},{"id":"W8QqAYKdOqks","cell_type":"markdown","source":"### Create Prompts","metadata":{"id":"W8QqAYKdOqks"}},{"id":"mjj7u1MaON3c","cell_type":"code","source":"zero_shot_combination = [(system_prompt_01, zs_user_prompt_01), (system_prompt_02, zs_user_prompt_02)]\nfew_shot_combination = [(system_prompt_01, fs_user_promps_01), (system_prompt_02, fs_user_promps_02)]\nzero_shot_final_prompts = [get_message(prompt) for prompt in zero_shot_combination]\nfew_shot_final_prompts = [get_message(prompt) for prompt in few_shot_combination]\nprompts = {\n    \"zs_fa\": zero_shot_final_prompts[0],\n    \"zs_en\": zero_shot_final_prompts[1],\n    \"few_fa\": few_shot_final_prompts[0],\n    \"few_en\": few_shot_final_prompts[1]\n}","metadata":{"id":"mjj7u1MaON3c","trusted":true},"outputs":[],"execution_count":null},{"id":"a3bca818-eab7-4e51-8db0-1e10c9345902","cell_type":"markdown","source":"## Experiments","metadata":{}},{"id":"1b989136-bbbf-49cd-83ac-bc3fde1df0e7","cell_type":"code","source":"def generate_result(df, run_func ,tokenizer, model):\n    \n    df.loc[:, 'zs_fa'] = None\n    df.loc[:, 'zs_en'] = None\n    df.loc[:, 'few_fa'] = None\n    df.loc[:, 'few_en'] = None\n\n    total_steps = len(df) * len(prompts)\n\n    with tqdm(total=total_steps, desc=\"Processing\") as pbar:\n        for index, row in df.iterrows():\n            copy_prompts = copy.deepcopy(prompts)\n            for k, v in copy_prompts.items():\n                v[1]['content'] = v[1]['content'].replace(\"REVIEW\", row['review'])\n                result = run_func(v, tokenizer, model)\n                df.at[index, k] = result\n                pbar.update(1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b5b3afa2-9ec0-4a90-a438-fd079494f6f2","cell_type":"markdown","source":"### PartAI/Dorna2-Llama3.1-8B-Instruct","metadata":{}},{"id":"c2256095-996f-46a6-9f6a-d0a91c3c3c4e","cell_type":"code","source":"def part_run(prompt, tokenizer, model):    \n    model.generation_config.temperature=None\n    model.generation_config.top_p=None\n    \n    input_ids = tokenizer.apply_chat_template(\n        prompt,\n        add_generation_prompt=True,\n        return_tensors=\"pt\",\n        return_attention_mask=True\n    ).to(model.device)\n\n    pad_token_id = tokenizer.pad_token_id or tokenizer.eos_token_id\n    attention_mask = (input_ids != pad_token_id).long()\n\n    terminators = [\n        tokenizer.eos_token_id,\n        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n    ]\n\n    outputs = model.generate(\n        input_ids,\n        #attention_mask=attention_mask,\n        pad_token_id=pad_token_id,\n        max_new_tokens=5,\n        eos_token_id=terminators,\n        do_sample=False,        # deterministic classification\n    )\n    response = outputs[0][input_ids.shape[-1]:]\n    return tokenizer.decode(response, skip_special_tokens=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"76d8a2d8-0d98-4df3-a3bf-7d8cd99faaf6","cell_type":"code","source":"model_1_result = sub_df.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f742717d-3773-4ac3-ac96-975dc77224ef","cell_type":"code","source":"model_path = \"PartAI/Dorna2-Llama3.1-8B-Instruct\"\ntokenizer_part_8b = AutoTokenizer.from_pretrained(model_path)\nmodel_part_8b = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4839d53e-56c5-4c50-abbf-992410afe733","cell_type":"code","source":"generate_result(model_1_result, part_run, tokenizer_part_8b, model_part_8b)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"89a17d33-5f70-48a4-850e-6abc0827092a","cell_type":"code","source":"model_1_result.to_csv('/kaggle/working/part_dorna_8b_7.csv')\nmodel_1_result.head(20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8c53b0e2-0989-4cdc-aabb-9e93194fc802","cell_type":"markdown","source":"### universitytehran/PersianMind-v1.0","metadata":{}},{"id":"6f557259-ac2e-4c1e-be38-3d36a221de82","cell_type":"code","source":"def remove_brackets_content(text):\n    text = re.sub(r'\\s*\\([^)]*\\)', '', text)\n    return text.rstrip('\\n')  \n    \ndef ut_run(prompt, tokenizer, model):   \n    model.generation_config.temperature=None\n    model.generation_config.top_p=None\n\n    TEMPLATE = \"{context}\\n{prompt}\"\n    CONTEXT = prompt[0]['content']\n    PROMPT = remove_brackets_content(prompt[1]['content'])\n    \n    model_input = TEMPLATE.format(context=CONTEXT, prompt=PROMPT)\n    input_tokens = tokenizer(model_input, return_tensors=\"pt\")\n    input_tokens = input_tokens.to(model.device)\n    generate_ids = model.generate(**input_tokens, \n                                  max_new_tokens=1024, \n                                  do_sample=False, \n                                  repetition_penalty=1.1)\n    model_output = tokenizer.batch_decode(generate_ids, \n                                          skip_special_tokens=True, \n                                          clean_up_tokenization_spaces=False)[0]\n    return model_output[len(model_input):].strip()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5b3ffe36-a07f-4554-b300-39884d52cbdc","cell_type":"code","source":"model_2_result = sub_df.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6f225c60-33d9-4548-a13f-70a8b996d9ad","cell_type":"code","source":"model_path = \"universitytehran/PersianMind-v1.0\"\ntokenizer_ut_7b = AutoTokenizer.from_pretrained(model_path)\nmodel_ut_7b = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a872860b-31bf-4312-9102-e2191d55c50f","cell_type":"code","source":"generate_result(model_2_result, ut_run, tokenizer_ut_7b, model_ut_7b)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8537e982-e9f8-4c3e-982e-079e8b8f1bb1","cell_type":"code","source":"model_2_result.to_csv('/kaggle/working/ut_mind_7b_1.csv')\nmodel_2_result.head(20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d7aa1b9f-75f6-4b3f-b591-64d5b26e9e11","cell_type":"markdown","source":"### CohereLabs/aya-expanse-8b","metadata":{}},{"id":"d9bd29e8-5882-4622-9219-ac186c64660d","cell_type":"code","source":"def aya_run(prompt, tokenizer, model):\n    input_ids = tokenizer.apply_chat_template(prompt, \n                                              tokenize=True, \n                                              add_generation_prompt=True, \n                                              return_tensors=\"pt\")\n    \n    gen_tokens = model.generate(\n        input_ids, \n        max_new_tokens=5, \n        do_sample=False\n        )\n    \n    generated = gen_tokens[0][input_ids.shape[-1]:]\n    gen_text = tokenizer.decode(generated, skip_special_tokens=True)\n    return gen_text.strip()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d14dbced-11f3-421e-9799-d9cb34f4f31f","cell_type":"code","source":"model_3_result = sub_df.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"de5e8c5e-5bc1-4330-a20e-b0fa0efc0e04","cell_type":"code","source":"model_path = \"CohereLabs/aya-expanse-8b\"\ntokenizer_aya_8b = AutoTokenizer.from_pretrained(model_path)\nmodel_aya_8b = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b9bc9518-2fb1-4a9d-9005-e1ed4ef1b00f","cell_type":"code","source":"generate_result(model_3_result, aya_run, tokenizer_aya_8b, model_aya_8b)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8c8798e3-ddae-4fda-b0cc-9a2c1107cee6","cell_type":"code","source":"model_3_result.to_csv('/kaggle/working/cohere_aya_8b.csv')\nmodel_3_result.head(20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"45739cce-90f3-4397-a0fd-e47e1c53b229","cell_type":"markdown","source":"### MaralGPT/Maral-7B-alpha-1","metadata":{}},{"id":"f578abb8-75dd-4921-b533-2d887093a975","cell_type":"code","source":"def remove_brackets_content(text):\n    text = re.sub(r'\\s*\\([^)]*\\)', '', text)\n    return text.rstrip('\\n')  \n    \ndef maral_run(prompt, tokenizer, model):\n    TEMPLATE = \"### Human:{context}{prompt}\"\n    CONTEXT = prompt[0]['content']\n    PROMPT = remove_brackets_content(prompt[1]['content'])\n    \n    model_input = TEMPLATE.format(context=CONTEXT, prompt=PROMPT)\n    inputs = tokenizer(model_input, return_tensors=\"pt\").to(model.device)\n    \n    generation_config = GenerationConfig(\n        do_sample=False,\n        max_new_tokens=5,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    \n    outputs = model.generate(**inputs, generation_config=generation_config)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)[len(model_input):].strip()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6dfd3f3c-cc64-4863-b0fc-54fb8a740916","cell_type":"code","source":"model_4_result = sub_df.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f14138ad-11e2-4898-a1b9-f622f9fa14ec","cell_type":"code","source":"model_path = \"MaralGPT/Maral-7B-alpha-1\"\ntokenizer_maral_7b = AutoTokenizer.from_pretrained(model_path)\nmodel_maral_7b = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f9b0df87-0d11-4e72-9132-1bc7e053cf0b","cell_type":"code","source":"generate_result(model_4_result, maral_run, tokenizer_maral_7b, model_maral_7b)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"16728673-a852-4bac-a8cc-89f53bf4534b","cell_type":"code","source":"model_4_result.to_csv('/kaggle/working/maral_7b.csv')\nmodel_4_result.head(20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fcfa590e-3f23-40e6-85bf-523d68b3c4b4","cell_type":"markdown","source":"### MehdiHosseiniMoghadam/AVA-Llama-3-V2","metadata":{}},{"id":"f90b392e-2b2c-441e-be19-b261a55c9a3f","cell_type":"code","source":"def remove_brackets_content(text):\n    text = re.sub(r'\\s*\\([^)]*\\)', '', text)\n    return text.rstrip('\\n')  \n    \ndef ava_run(prompt, tokenizer, model):\n    TEMPLATE = \"### Human:{context}{prompt}\"\n    CONTEXT = prompt[0]['content']\n    PROMPT = remove_brackets_content(prompt[1]['content'])\n    \n    model_input = TEMPLATE.format(context=CONTEXT, prompt=PROMPT)\n    inputs = tokenizer(model_input, return_tensors=\"pt\").to(model.device)\n    \n    generation_config = GenerationConfig(\n        do_sample=False,\n        max_new_tokens=5,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    \n    outputs = model.generate(**inputs, generation_config=generation_config)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)[len(model_input):].strip()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"aed05872-3fa5-4bed-9d26-e720f7f8d799","cell_type":"code","source":"model_5_result = sub_df.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9bd6638c-3ee2-4ab5-b42f-041fda00801a","cell_type":"code","source":"model_path = \"MaralGPT/Maral-7B-alpha-1\"\ntokenizer_ava_8b = AutoTokenizer.from_pretrained(model_path)\nmodel_ava_8b = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c5869e31-9b07-4d97-ba54-14fc8fb0e39b","cell_type":"code","source":"generate_result(model_5_result, ava_run, tokenizer_ava_8b, model_ava_8b)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9d29d39f-b4ad-43df-b763-f1d8213316d8","cell_type":"code","source":"model_5_result.to_csv('/kaggle/working/ava_8b.csv')\nmodel_5_result.head(20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dbe0c789-3a42-41ca-a120-f59f61836b88","cell_type":"markdown","source":"### ViraIntelligentDataMining/PersianLLaMA-13B-Instruct","metadata":{}},{"id":"f1290710-507a-4fb1-a363-ead3faa6dfd6","cell_type":"code","source":"def remove_brackets_content(text):\n    text = re.sub(r'\\s*\\([^)]*\\)', '', text)\n    return text.rstrip('\\n')  \n    \ndef persian_llama_run(prompt, tokenizer, model):\n    TEMPLATE = \"### Instruction:{context}{prompt}\"\n    CONTEXT = prompt[0]['content']\n    PROMPT = remove_brackets_content(prompt[1]['content'])\n    \n    model_input = TEMPLATE.format(context=CONTEXT, prompt=PROMPT)\n    inputs = tokenizer(model_input, return_tensors=\"pt\").to(model.device)\n    \n    generation_config = GenerationConfig(\n        do_sample=False,\n        max_new_tokens=5,\n        pad_token_id=tokenizer.eos_token_id,\n        eos_token_id=tokenizer.eos_token_id,\n    )\n    \n    outputs = model.generate(**inputs, generation_config=generation_config)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)[len(model_input):].strip()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fc8260c6-71c6-4bb0-b1bd-ef8e84671630","cell_type":"code","source":"model_6_result = sub_df.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"08073005-f6c7-445a-bf82-2643440ff305","cell_type":"code","source":"model_path = \"ViraIntelligentDataMining/PersianLLaMA-13B-Instruct\"\ntokenizer_persian_llama_13b = LlamaTokenizer.from_pretrained(model_path)\nmodel_persian_llama_13b = LlamaForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1656a1a3-e83f-4071-b8a9-ec83729867ee","cell_type":"code","source":"generate_result(model_6_result, persian_llama_run, tokenizer_persian_llama_13b, model_persian_llama_13b)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a0ee5cac-fce9-48ad-a7d5-cbad5b48c0ac","cell_type":"code","source":"model_6_result.to_csv('/kaggle/working/persian_llama_13b.csv')\nmodel_6_result.head(20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"387d6840-5755-4cb9-8282-0de9d660da84","cell_type":"markdown","source":"## Result","metadata":{}},{"id":"d784bc19-4630-4ab4-82d9-1b1bc914b1b5","cell_type":"code","source":"def map_sentiment(df):\n    def standardize_value(value):\n        sentiments = set(label_en_fa.keys())\n        if value in sentiments:\n            return value\n        elif value in label_fa_en:\n            return label_fa_en[value]\n        else:\n            return \"-\"\n    \n    experiment_keys = list(prompts.keys())\n    for exp in experiment_keys:\n        df[exp] = df[exp].apply(standardize_value)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c2bc760b-d7c8-4801-afd0-b2fdb63e1afd","cell_type":"code","source":"def plot_confusion_matrix(df):\n    labels = ['POSITIVE', 'NEGATIVE', 'NEUTRAL', 'OTHER']\n    prediction_columns = list(prompts.keys())\n    \n    num_preds = len(prediction_columns)\n    cols = 2\n    rows = (num_preds + 1) // cols\n    \n    fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 5 * rows))\n    axes = axes.flatten()\n\n    for i, pred_col in enumerate(prediction_columns):\n        cm = confusion_matrix(df['sentiment'], df[pred_col], labels=labels)\n        cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n    \n        sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', ax=axes[i], cbar=False)\n        axes[i].set_title(f'Confusion Matrix: {pred_col}')\n        axes[i].set_xlabel('Predicted')\n        axes[i].set_ylabel('True')\n\n    for j in range(i + 1, len(axes)):\n        fig.delaxes(axes[j])\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"08161cf7-1e8a-4607-b532-0c989da47d51","cell_type":"code","source":"def calculate_metrics(df):\n    labels = ['POSITIVE', 'NEGATIVE', 'NEUTRAL', 'OTHER']\n    prediction_columns = list(prompts.keys())\n\n    results = {}\n\n    for i, pred_col in enumerate(prediction_columns):\n        report = classification_report(df['sentiment'], df[pred_col], labels=labels, output_dict=True, zero_division=0)\n        report_df = pd.DataFrame(report).transpose()\n        report_df = report_df.round(3)\n        results[pred_col] = report_df\n\n    return results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"419678ad-de6b-4915-a0a9-81c2a5516dfb","cell_type":"code","source":"def show_metrics_grid(df, columns=2):\n    metrics_dict = calculate_metrics(df)\n    dfs = list(metrics_dict.values())\n    titles = list(metrics_dict.keys())\n\n    html_tables = [\n        f\"<div style='padding:10px'><h4 style='text-align:center'>Experiment: {title}</h4>{df.to_html()}</div>\"\n        for title, df in zip(titles, dfs)\n    ]\n\n    rows = [\n        ''.join(html_tables[i:i+columns])\n        for i in range(0, len(html_tables), columns)\n    ]\n\n    grid_html = '<table><tr><td>' + '</td><td>'.join(rows) + '</td></tr></table>'\n    display_html(grid_html, raw=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c9ec26f9-c718-4a1f-bbda-be69d9407071","cell_type":"markdown","source":"### PartAI/Dorna2-Llama3.1-8B-Instruct","metadata":{}},{"id":"58643cb7-59d4-427c-8e5e-185a9cc09ddf","cell_type":"code","source":"map_sentiment(model_1_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e1ff48c1-3d08-4316-956e-cfc68d81c411","cell_type":"code","source":"plot_confusion_matrix(model_1_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0791e053-5fd2-4484-9bdd-cc8e55b9f405","cell_type":"code","source":"show_metrics_grid(model_1_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"753b50a9-0763-4005-b86a-89e7d0764243","cell_type":"markdown","source":"### universitytehran/PersianMind-v1.0","metadata":{}},{"id":"be360dac-8e4a-4539-84cc-503b4e729230","cell_type":"code","source":"map_sentiment(model_2_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"433d1aff-eeaf-46f2-9f12-eb200bcc8c0e","cell_type":"code","source":"plot_confusion_matrix(model_2_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"43a56566-7593-4590-be69-d08d607433b4","cell_type":"code","source":"show_metrics_grid(model_2_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9429ffe3-b803-485c-ad0b-429b73dde59e","cell_type":"markdown","source":"### CohereLabs/aya-expanse-8b","metadata":{}},{"id":"e9894c83-9cc6-4b8e-aab7-883785ee5563","cell_type":"code","source":"map_sentiment(model_3_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7681119b-d907-4a68-b622-b91cfb77e6f8","cell_type":"code","source":"plot_confusion_matrix(model_3_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"52be328f-818a-4304-b37e-79acdaba14f7","cell_type":"code","source":"show_metrics_grid(model_3_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4b372be0-b775-4ff3-8da2-b732055ed918","cell_type":"markdown","source":"### MaralGPT/Maral-7B-alpha-1","metadata":{}},{"id":"84dc0280-e1fd-44a0-aa5f-01e75c68d1cc","cell_type":"code","source":"map_sentiment(model_4_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c906f1b9-0848-4db7-bb5e-a745f1a7a428","cell_type":"code","source":"plot_confusion_matrix(model_4_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"52ab4a4a-52fd-44e9-9e30-c9f9ad374ddb","cell_type":"code","source":"show_metrics_grid(model_4_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d0905b81-c852-4f0d-ac42-54d8c38a5376","cell_type":"markdown","source":"### MehdiHosseiniMoghadam/AVA-Llama-3-V2","metadata":{}},{"id":"b1e04247-695a-4ed6-ab07-0d5f6d37da03","cell_type":"code","source":"map_sentiment(model_5_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f8d03960-55ec-42e5-b69e-5730aaee02fd","cell_type":"code","source":"plot_confusion_matrix(model_5_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b2b065ba-a5e3-421f-a6a1-dcbe2147e2f2","cell_type":"code","source":"show_metrics_grid(model_5_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"768d7a6c-cb48-4a58-bb31-a1024e8cf35e","cell_type":"markdown","source":"### ViraIntelligentDataMining/PersianLLaMA-13B-Instruct","metadata":{}},{"id":"f19fb451-69ac-4a6a-98fd-7fadbd67f6c8","cell_type":"code","source":"map_sentiment(model_6_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"02eb6b60-5283-451d-93a8-5a1e2ef9ba88","cell_type":"code","source":"plot_confusion_matrix(model_6_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"853d1be8-7de3-4ffd-bc76-56c623e031d7","cell_type":"code","source":"show_metrics_grid(model_6_result)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}