{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"aT16Td1MIT3V","cell_type":"markdown","source":"# MEng Computer Science Thesis Implementation","metadata":{"id":"aT16Td1MIT3V"}},{"id":"XFL1Y7LyIpoS","cell_type":"markdown","source":"**Title:** Benchmarking Persian LLMs Versus State-of-the-Art NLP Models for Sentiment Analysis <br/>\n**Student Name:** Seyyed Jalal Tabatabaee <br/>\n**Student ID:** GH1033801 <br/>\n**Supervisor:** Prof. Dr. Reza Babaei <br/>\n**Semester:** Summer 2025 <br/>\n**University:** Gisma University of Applied Sciences <br/>\n**Github Link:** https://github.com/shayantabatabaee/llm-sentiment-analysis <br/>\n**Dataset Link:** https://github.com/persiannlp/parsinlu\n\n","metadata":{"id":"XFL1Y7LyIpoS"}},{"id":"mMeYL647MjUI","cell_type":"markdown","source":"### Introduction","metadata":{"id":"mMeYL647MjUI"}},{"id":"tn7uw8z0Mn26","cell_type":"markdown","source":"This project focuses on sentiment analysis for the Persian language, a low-resource language that has been underexplored in modern NLP research. While most sentiment analysis studies have been conducted in English, Persian poses unique challenges due to its complex grammar, diverse vocabulary, and the absence of diacritics.\n\nTraditional approaches to sentiment analysis involve steps like text preprocessing, embedding generation, and classification using machine learning (ML) or deep learning (DL) models. However, with the emergence of large language models (LLMs) such as ChatGPT, new techniques like zero-shot and few-shot prompting have shown promising results — even without fine-tuning.\n\nThis research benchmarks Persian LLMs (with fewer parameters) on the ParsiNLU sentiment dataset and compares their performance against state-of-the-art traditional models like BERT. The goal is to investigate whether smaller, Persian-specific LLMs can offer performance comparable to larger multilingual models while being more cost-efficient and practical for real-world applications.\n\n","metadata":{"id":"tn7uw8z0Mn26"}},{"id":"TtxvszToM1ob","cell_type":"markdown","source":"### Install Libraries","metadata":{"id":"TtxvszToM1ob"}},{"id":"Nwd50n3RMpI2","cell_type":"code","source":"# !pip install -q datasets\n# !pip install -q pandas\n# !pip install -q torch\n# !pip install -q transformers\n# !pip install -U -q accelerate\n# !pip install -q tqdm\n# !pip install -q scikit-learn\n# !pip install -q seaborn\n# !pip install -q numpy","metadata":{"id":"Nwd50n3RMpI2","trusted":true},"outputs":[],"execution_count":null},{"id":"MqTYfjNhNrFH","cell_type":"markdown","source":"### Import Libraries","metadata":{"id":"MqTYfjNhNrFH"}},{"id":"cf179213-c445-4aff-a6ec-f22935bd68de","cell_type":"code","source":"import os\n\nos.environ[\"FORCE_TF_AVAILABLE\"] = \"0\"\nos.environ[\"USE_TF\"]=\"0\"","metadata":{"trusted":true,"id":"cf179213-c445-4aff-a6ec-f22935bd68de"},"outputs":[],"execution_count":null},{"id":"kjCE-NESNYwp","cell_type":"code","source":"import re\nimport copy\nimport math\nimport torch\nimport transformers\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom datasets import load_dataset\nfrom kaggle_secrets import UserSecretsClient\nfrom IPython.display import display, display_html\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, LlamaTokenizer, LlamaForCausalLM\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score","metadata":{"id":"kjCE-NESNYwp","trusted":true},"outputs":[],"execution_count":null},{"id":"TiQpdjLNS2kO","cell_type":"markdown","source":"### Initialize Variables","metadata":{"id":"TiQpdjLNS2kO"}},{"id":"41E5HYEGS751","cell_type":"code","source":"DATASET_URL = \"https://raw.githubusercontent.com/persiannlp/parsinlu/master/data/sentiment-analysis/food.jsonl\"\nLABEL_MAP = {\n    \"3\": \"OTHER\",\n    \"2\": \"POSITIVE\",\n    \"1\": \"POSITIVE\",\n    \"0\": \"NEUTRAL\",\n    \"-1\": \"NEGATIVE\",\n    \"-2\": \"NEGATIVE\"\n}\nTEST_COUNT = 190\nRANDOM_STATE = 18\nos.environ['HF_TOKEN'] = UserSecretsClient().get_secret(\"HF_TOKEN\")","metadata":{"id":"41E5HYEGS751","trusted":true},"outputs":[],"execution_count":null},{"id":"7M0zcXzwg7tm","cell_type":"code","source":"label_en_fa = {\n    \"OTHER\": \"سایر\",\n    \"POSITIVE\": \"مثبت\",\n    \"NEUTRAL\": \"خنثی\",\n    \"NEGATIVE\": \"منفی\"\n}\nlabel_fa_en = {v:k for k,v in label_en_fa.items()}","metadata":{"id":"7M0zcXzwg7tm","trusted":true},"outputs":[],"execution_count":null},{"id":"03uecM7sOaxr","cell_type":"markdown","source":"## Dataset Preprocessing","metadata":{"id":"03uecM7sOaxr"}},{"id":"LtUCtvETYmq-","cell_type":"markdown","source":"To ensure a direct comparison with the baseline study [(Abaskohi et al., 2024)](https://arxiv.org/pdf/2404.02403), we used the same dataset and fixed the random seed. Additionally, we merged the original six sentiment categories into four, matching the label structure used in the baseline. The original dataset contains six labels: *VERY_POSITIVE, POSITIVE, NEUTRAL, NEGATIVE, VERY_NEGATIVE,* and *OTHER*. For our analysis, we merged *VERY_POSITIVE* with *POSITIVE* and *VERY_NEGATIVE* with *NEGATIVE*.","metadata":{"id":"LtUCtvETYmq-"}},{"id":"C0cZTb3SYgF_","cell_type":"markdown","source":"### Load Dataset","metadata":{"id":"C0cZTb3SYgF_"}},{"id":"4d-qNn9FOkTa","cell_type":"code","source":"dataset = load_dataset(\"json\", data_files=DATASET_URL)\ndf = dataset['train'].to_pandas()\ndf = df[['review', 'sentiment']]\ndf['sentiment'] = df['sentiment'].map(LABEL_MAP)","metadata":{"id":"4d-qNn9FOkTa","trusted":true},"outputs":[],"execution_count":null},{"id":"SrLr_OtNgkol","cell_type":"code","source":"sub_df = df.sample(n=TEST_COUNT, random_state=RANDOM_STATE)","metadata":{"id":"SrLr_OtNgkol","trusted":true},"outputs":[],"execution_count":null},{"id":"nv_62kpadn71","cell_type":"markdown","source":"### Visualize Dataset","metadata":{"id":"nv_62kpadn71"}},{"id":"KTJnCoKXXUaI","cell_type":"code","source":"def insight(data):\n  print(f\"Dataset shape: {data.shape}\", end=\"\\n\\n\")\n  print(\"Five sample of data\")\n  display(data.head(5))\n  print(\"\\n\\nDataset info\", end=\"\\n\\n\")\n  display(data['sentiment'].value_counts())\n  data['sentiment'].value_counts().plot.bar(x=\"Sentiment\", y=\"Count\", rot=45)","metadata":{"id":"KTJnCoKXXUaI","trusted":true},"outputs":[],"execution_count":null},{"id":"vPGDO_M5fG0_","cell_type":"code","source":"insight(df)","metadata":{"id":"vPGDO_M5fG0_","trusted":true},"outputs":[],"execution_count":null},{"id":"SKrk0hi4eHzT","cell_type":"code","source":"insight(sub_df)","metadata":{"id":"SKrk0hi4eHzT","trusted":true},"outputs":[],"execution_count":null},{"id":"1ap-MKdmIEaj","cell_type":"markdown","source":"## Prompts","metadata":{"id":"1ap-MKdmIEaj"}},{"id":"rTrsIbzhQ2aK","cell_type":"code","source":"def get_message(prompt):\n  return [{\"role\": \"system\", \"content\": prompt[0]},{\"role\": \"user\", \"content\": prompt[1]}]","metadata":{"id":"rTrsIbzhQ2aK","trusted":true},"outputs":[],"execution_count":null},{"id":"JXW7wIp5LD0v","cell_type":"markdown","source":"### System Prompts","metadata":{"id":"JXW7wIp5LD0v"}},{"id":"G63BOFJiLJTH","cell_type":"code","source":"system_prompt_01 = \"\"\"\nتو یک دستیار هوشمند برای تحلیل احساسات هستی.\nیک نظر کوتاه درباره ی غذا به زبان فارسی دریافت میکنی.\nوظیفه‌ی تو این است که احساس کلی نظر را در یکی از چهار دسته‌ی زیر طبقه‌بندی کنی:\n\n- مثبت\n- منفی\n- خنثی\n- سایر\n\nفقط یکی از این چهار برچسب را برگردان. هیچ متن اضافی، توضیح، یا عبارتی مانند «احساس:» در پاسخ ننویس.\nاگر احساس نظر نامشخص، متناقض یا ترکیبی بود، فقط برچسب «سایر» را برگردان\nاگر حس متن مثبت یا منفی نبود خنثی را برگردان\n\"\"\"","metadata":{"id":"G63BOFJiLJTH","trusted":true},"outputs":[],"execution_count":null},{"id":"a_ZJuoAxM7jV","cell_type":"code","source":"system_prompt_02 = \"\"\"\nYou are an AI assistant for sentiment analysis.\nYou will receive a short user opinion about food, written in Persian.\nYour task is to classify the overall sentiment of the opinion as one of the following four categories:\n\n- POSITIVE\n- NEGATIVE\n- NEUTRAL\n- OTHER\n\nReturn ONLY one of the four labels listed above. Do not include any additional text, explanations, or prefixes such as 'Sentiment:'.\nIf the sentiment is unclear, contradictory, or mixed, return OTHER.\nIf the sentiment is not POSITIVE or NEGATIVE return NEUTRAL.\n\"\"\"","metadata":{"id":"a_ZJuoAxM7jV","trusted":true},"outputs":[],"execution_count":null},{"id":"MrDTOlt4NjvS","cell_type":"markdown","source":"### Zero-Shot User Prompts","metadata":{"id":"MrDTOlt4NjvS"}},{"id":"a5FHkTatNhAu","cell_type":"code","source":"zs_user_prompt_01= \"\"\"\nنظر: REVIEW\nاحساس (مثبت، منفی، خنثی، سایر):\n\"\"\"","metadata":{"id":"a5FHkTatNhAu","trusted":true},"outputs":[],"execution_count":null},{"id":"hhJhoTg-OFaY","cell_type":"code","source":"zs_user_prompt_02=\"\"\"\nReview: REVIEW\nSentiment (POSITIVE, NEGATIVE, NEUTRAL, OTHER):\n\"\"\"","metadata":{"id":"hhJhoTg-OFaY","trusted":true},"outputs":[],"execution_count":null},{"id":"KcCox2-hSz9K","cell_type":"markdown","source":"### Few-Shot User Prompts","metadata":{"id":"KcCox2-hSz9K"}},{"id":"FDqt3DbtTde_","cell_type":"code","source":"diff_df = df.loc[~df.index.isin(sub_df.index)]\ndef create_examples_df(df, n_samples):\n    groups = df['sentiment'].unique()\n    sampled = []\n\n    for sentiment in groups:\n        group_df = df[df['sentiment'] == sentiment]\n        sampled_df = group_df.sample(n=n_samples, random_state=RANDOM_STATE)\n        sampled.append(sampled_df)\n\n    return pd.concat(sampled).sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)","metadata":{"id":"FDqt3DbtTde_","trusted":true},"outputs":[],"execution_count":null},{"id":"K4nzoexQfnCr","cell_type":"code","source":"def create_example_prompts(n_samples):\n  examples_df = create_examples_df(diff_df, n_samples)\n  en_examples = \"\"\n  fa_examples = \"\"\n  for i, row in examples_df.iterrows():\n    en_examples += f\"Example {i+1}:\\n\"\n    en_examples += f\"Review: {row['review']}\\n\"\n    en_examples += f\"Sentiment: {row['sentiment']}\\n\"\n\n    fa_examples += f\"مثال {i+1}:\\n\"\n    fa_examples += f\"نظر: {row['review']}\\n\"\n    fa_examples += f\"احساس: {label_en_fa[row['sentiment']]}\\n\"\n\n  return en_examples, fa_examples","metadata":{"id":"K4nzoexQfnCr","trusted":true},"outputs":[],"execution_count":null},{"id":"914abfce-a3e6-41ed-96c3-fd0b22106232","cell_type":"markdown","source":"#### One-Shot User Prompts","metadata":{}},{"id":"tlvaH3mzhPU7","cell_type":"code","source":"en_1_examples, fa_1_examples = create_example_prompts(1)\nprint(en_1_examples)\nprint(\"*\" * 50)\nprint(fa_1_examples)","metadata":{"id":"tlvaH3mzhPU7","trusted":true},"outputs":[],"execution_count":null},{"id":"p2YRuI69b_dI","cell_type":"code","source":"fs_1_user_prompts_01 = f\"\"\"\nمثالها:\n{fa_1_examples}\n\nنظر: REVIEW\nاحساس (مثبت، منفی، خنثی، سایر):\n\"\"\"","metadata":{"id":"p2YRuI69b_dI","trusted":true},"outputs":[],"execution_count":null},{"id":"qoHeHPFPcC3Y","cell_type":"code","source":"fs_1_user_prompts_02 = f\"\"\"\nExamples:\n{en_1_examples}\n\nReview: REVIEW\nSentiment (POSITIVE, NEGATIVE, NEUTRAL, OTHER):\n\"\"\"","metadata":{"id":"qoHeHPFPcC3Y","trusted":true},"outputs":[],"execution_count":null},{"id":"28e1ab5f-21eb-4a21-917f-45d7a5cc5bad","cell_type":"markdown","source":"#### Three-Shot User Prompts","metadata":{}},{"id":"0cad6752-8bea-44de-b6de-10ce47e565b3","cell_type":"code","source":"en_3_examples, fa_3_examples = create_example_prompts(3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bda114af-f62a-4973-9d01-c2a864fe1e03","cell_type":"code","source":"fs_3_user_prompts_01 = f\"\"\"\nمثالها:\n{fa_3_examples}\n\nنظر: REVIEW\nاحساس (مثبت، منفی، خنثی، سایر):\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2dc8e2f6-0ced-40e4-9c63-d79f45759555","cell_type":"code","source":"fs_3_user_prompts_02 = f\"\"\"\nExamples:\n{en_3_examples}\n\nReview: REVIEW\nSentiment (POSITIVE, NEGATIVE, NEUTRAL, OTHER):\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"W8QqAYKdOqks","cell_type":"markdown","source":"### Create Prompts","metadata":{"id":"W8QqAYKdOqks"}},{"id":"mjj7u1MaON3c","cell_type":"code","source":"zero_shot_combination = [(system_prompt_01, zs_user_prompt_01), (system_prompt_02, zs_user_prompt_02)]\nfew_shot_combination = [\n    (system_prompt_01, fs_1_user_prompts_01), \n    (system_prompt_02, fs_1_user_prompts_02),\n    (system_prompt_01, fs_3_user_prompts_01),\n    (system_prompt_02, fs_3_user_prompts_02)]\nzero_shot_final_prompts = [get_message(prompt) for prompt in zero_shot_combination]\nfew_shot_final_prompts = [get_message(prompt) for prompt in few_shot_combination]\nprompts = {\n    \"zs_fa\": zero_shot_final_prompts[0],\n    \"zs_en\": zero_shot_final_prompts[1],\n    \"few_1_fa\": few_shot_final_prompts[0],\n    \"few_1_en\": few_shot_final_prompts[1],\n    \"few_3_fa\": few_shot_final_prompts[2],\n    \"few_3_en\": few_shot_final_prompts[3]\n}","metadata":{"id":"mjj7u1MaON3c","trusted":true},"outputs":[],"execution_count":null},{"id":"a3bca818-eab7-4e51-8db0-1e10c9345902","cell_type":"markdown","source":"## Experiments","metadata":{"id":"a3bca818-eab7-4e51-8db0-1e10c9345902"}},{"id":"1b989136-bbbf-49cd-83ac-bc3fde1df0e7","cell_type":"code","source":"def generate_result(df, run_func ,tokenizer, model):\n\n    df.loc[:, 'zs_fa'] = None\n    df.loc[:, 'zs_en'] = None\n    df.loc[:, 'few_1_fa'] = None\n    df.loc[:, 'few_1_en'] = None\n    df.loc[:, 'few_3_fa'] = None\n    df.loc[:, 'few_3_en'] = None\n\n    total_steps = len(df) * len(prompts)\n\n    with tqdm(total=total_steps, desc=\"Processing\") as pbar:\n        for index, row in df.iterrows():\n            copy_prompts = copy.deepcopy(prompts)\n            for k, v in copy_prompts.items():\n                v[1]['content'] = v[1]['content'].replace(\"REVIEW\", row['review'])\n                result = run_func(v, tokenizer, model)\n                df.at[index, k] = result\n                pbar.update(1)","metadata":{"trusted":true,"id":"1b989136-bbbf-49cd-83ac-bc3fde1df0e7"},"outputs":[],"execution_count":null},{"id":"48d1e74f-69c3-4640-914c-cbed15050c51","cell_type":"code","source":"def cleanup():\n    import torch    \n    import gc\n    import subprocess\n\n    subprocess.run([\"rm\", \"-rf\", \"/root/.cache/huggingface\"], check=True)\n    \n    while gc.collect()!=0:\n        for i in range(0,3):\n            torch.cuda.empty_cache()\n            torch.cuda.ipc_collect()\n            gc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b5b3afa2-9ec0-4a90-a438-fd079494f6f2","cell_type":"markdown","source":"### PartAI/Dorna2-Llama3.1-8B-Instruct","metadata":{"id":"b5b3afa2-9ec0-4a90-a438-fd079494f6f2"}},{"id":"c2256095-996f-46a6-9f6a-d0a91c3c3c4e","cell_type":"code","source":"def part_run(prompt, tokenizer, model):\n    model.generation_config.temperature=None\n    model.generation_config.top_p=None\n\n    input_ids = tokenizer.apply_chat_template(\n        prompt,\n        add_generation_prompt=True,\n        return_tensors=\"pt\",\n        return_attention_mask=True\n    ).to(model.device)\n\n    pad_token_id = tokenizer.pad_token_id or tokenizer.eos_token_id\n    attention_mask = (input_ids != pad_token_id).long()\n\n    terminators = [\n        tokenizer.eos_token_id,\n        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n    ]\n\n    outputs = model.generate(\n        input_ids,\n        #attention_mask=attention_mask,\n        pad_token_id=pad_token_id,\n        max_new_tokens=5,\n        eos_token_id=terminators,\n        do_sample=False,        # deterministic classification\n    )\n    response = outputs[0][input_ids.shape[-1]:]\n    return tokenizer.decode(response, skip_special_tokens=True)","metadata":{"trusted":true,"id":"c2256095-996f-46a6-9f6a-d0a91c3c3c4e"},"outputs":[],"execution_count":null},{"id":"76d8a2d8-0d98-4df3-a3bf-7d8cd99faaf6","cell_type":"code","source":"model_1_result = sub_df.copy()","metadata":{"trusted":true,"id":"76d8a2d8-0d98-4df3-a3bf-7d8cd99faaf6"},"outputs":[],"execution_count":null},{"id":"f742717d-3773-4ac3-ac96-975dc77224ef","cell_type":"code","source":"model_path = \"PartAI/Dorna2-Llama3.1-8B-Instruct\"\ntokenizer_part_8b = AutoTokenizer.from_pretrained(model_path)\nmodel_part_8b = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true,"id":"f742717d-3773-4ac3-ac96-975dc77224ef"},"outputs":[],"execution_count":null},{"id":"4839d53e-56c5-4c50-abbf-992410afe733","cell_type":"code","source":"generate_result(model_1_result, part_run, tokenizer_part_8b, model_part_8b)","metadata":{"trusted":true,"id":"4839d53e-56c5-4c50-abbf-992410afe733"},"outputs":[],"execution_count":null},{"id":"89a17d33-5f70-48a4-850e-6abc0827092a","cell_type":"code","source":"model_1_result.to_csv('/kaggle/working/part_dorna_8b.csv')\nmodel_1_result.head(20)","metadata":{"trusted":true,"id":"89a17d33-5f70-48a4-850e-6abc0827092a"},"outputs":[],"execution_count":null},{"id":"9944ebfd-e288-4d7e-9c95-b8203bd8e1b9","cell_type":"code","source":"del part_run\ndel tokenizer_part_8b\ndel model_part_8b\ncleanup()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8c53b0e2-0989-4cdc-aabb-9e93194fc802","cell_type":"markdown","source":"### universitytehran/PersianMind-v1.0","metadata":{"id":"8c53b0e2-0989-4cdc-aabb-9e93194fc802"}},{"id":"6f557259-ac2e-4c1e-be38-3d36a221de82","cell_type":"code","source":"def remove_brackets_content(text):\n    text = re.sub(r'\\s*\\([^)]*\\)', '', text)\n    return text.rstrip('\\n')\n\ndef ut_run(prompt, tokenizer, model):\n    model.generation_config.temperature=None\n    model.generation_config.top_p=None\n\n    TEMPLATE = \"{context}\\n{prompt}\"\n    CONTEXT = prompt[0]['content']\n    PROMPT = remove_brackets_content(prompt[1]['content'])\n\n    model_input = TEMPLATE.format(context=CONTEXT, prompt=PROMPT)\n    input_tokens = tokenizer(model_input, return_tensors=\"pt\")\n    input_tokens = input_tokens.to(model.device)\n    generate_ids = model.generate(**input_tokens,\n                                  max_new_tokens=1024,\n                                  do_sample=False,\n                                  repetition_penalty=1.1)\n    model_output = tokenizer.batch_decode(generate_ids,\n                                          skip_special_tokens=True,\n                                          clean_up_tokenization_spaces=False)[0]\n    return model_output[len(model_input):].strip()","metadata":{"trusted":true,"id":"6f557259-ac2e-4c1e-be38-3d36a221de82"},"outputs":[],"execution_count":null},{"id":"5b3ffe36-a07f-4554-b300-39884d52cbdc","cell_type":"code","source":"model_2_result = sub_df.copy()","metadata":{"trusted":true,"id":"5b3ffe36-a07f-4554-b300-39884d52cbdc"},"outputs":[],"execution_count":null},{"id":"6f225c60-33d9-4548-a13f-70a8b996d9ad","cell_type":"code","source":"model_path = \"universitytehran/PersianMind-v1.0\"\ntokenizer_ut_7b = AutoTokenizer.from_pretrained(model_path)\nmodel_ut_7b = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true,"id":"6f225c60-33d9-4548-a13f-70a8b996d9ad"},"outputs":[],"execution_count":null},{"id":"a872860b-31bf-4312-9102-e2191d55c50f","cell_type":"code","source":"generate_result(model_2_result, ut_run, tokenizer_ut_7b, model_ut_7b)","metadata":{"trusted":true,"id":"a872860b-31bf-4312-9102-e2191d55c50f"},"outputs":[],"execution_count":null},{"id":"8537e982-e9f8-4c3e-982e-079e8b8f1bb1","cell_type":"code","source":"model_2_result.to_csv('/kaggle/working/ut_mind_7b.csv')\nmodel_2_result.head(20)","metadata":{"trusted":true,"id":"8537e982-e9f8-4c3e-982e-079e8b8f1bb1"},"outputs":[],"execution_count":null},{"id":"fa74ccb0-b2d5-4ec3-9714-19be7eaa5e26","cell_type":"code","source":"del ut_run\ndel tokenizer_ut_7b\ndel model_ut_7b\ncleanup()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d7aa1b9f-75f6-4b3f-b591-64d5b26e9e11","cell_type":"markdown","source":"### CohereLabs/aya-expanse-8b","metadata":{"id":"d7aa1b9f-75f6-4b3f-b591-64d5b26e9e11"}},{"id":"d9bd29e8-5882-4622-9219-ac186c64660d","cell_type":"code","source":"def aya_run(prompt, tokenizer, model):\n    input_ids = tokenizer.apply_chat_template(prompt,\n                                              tokenize=True,\n                                              add_generation_prompt=True,\n                                              return_tensors=\"pt\").to(model.device)\n\n    gen_tokens = model.generate(\n        input_ids,\n        max_new_tokens=5,\n        do_sample=False\n        )\n\n    generated = gen_tokens[0][input_ids.shape[-1]:]\n    gen_text = tokenizer.decode(generated, skip_special_tokens=True)\n    return gen_text.strip()","metadata":{"trusted":true,"id":"d9bd29e8-5882-4622-9219-ac186c64660d"},"outputs":[],"execution_count":null},{"id":"d14dbced-11f3-421e-9799-d9cb34f4f31f","cell_type":"code","source":"model_3_result = sub_df.copy()","metadata":{"trusted":true,"id":"d14dbced-11f3-421e-9799-d9cb34f4f31f"},"outputs":[],"execution_count":null},{"id":"de5e8c5e-5bc1-4330-a20e-b0fa0efc0e04","cell_type":"code","source":"model_path = \"CohereLabs/aya-expanse-8b\"\ntokenizer_aya_8b = AutoTokenizer.from_pretrained(model_path)\nmodel_aya_8b = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true,"id":"de5e8c5e-5bc1-4330-a20e-b0fa0efc0e04"},"outputs":[],"execution_count":null},{"id":"b9bc9518-2fb1-4a9d-9005-e1ed4ef1b00f","cell_type":"code","source":"generate_result(model_3_result, aya_run, tokenizer_aya_8b, model_aya_8b)","metadata":{"trusted":true,"id":"b9bc9518-2fb1-4a9d-9005-e1ed4ef1b00f"},"outputs":[],"execution_count":null},{"id":"8c8798e3-ddae-4fda-b0cc-9a2c1107cee6","cell_type":"code","source":"model_3_result.to_csv('/kaggle/working/cohere_aya_8b.csv')\nmodel_3_result.head(20)","metadata":{"trusted":true,"id":"8c8798e3-ddae-4fda-b0cc-9a2c1107cee6"},"outputs":[],"execution_count":null},{"id":"942c5d67-ec03-4e50-b248-fcac0fa16bea","cell_type":"code","source":"del aya_run\ndel tokenizer_aya_8b\ndel model_aya_8b\ncleanup()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"45739cce-90f3-4397-a0fd-e47e1c53b229","cell_type":"markdown","source":"### MaralGPT/Maral-7B-alpha-1","metadata":{"id":"45739cce-90f3-4397-a0fd-e47e1c53b229"}},{"id":"f578abb8-75dd-4921-b533-2d887093a975","cell_type":"code","source":"def remove_brackets_content(text):\n    text = re.sub(r'\\s*\\([^)]*\\)', '', text)\n    return text.rstrip('\\n')\n\ndef maral_run(prompt, tokenizer, model):\n    TEMPLATE = \"### Human:{context}{prompt}\"\n    CONTEXT = prompt[0]['content']\n    PROMPT = remove_brackets_content(prompt[1]['content'])\n\n    model_input = TEMPLATE.format(context=CONTEXT, prompt=PROMPT)\n    inputs = tokenizer(model_input, return_tensors=\"pt\").to(model.device)\n\n    generation_config = GenerationConfig(\n        do_sample=False,\n        max_new_tokens=5,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    outputs = model.generate(**inputs, generation_config=generation_config)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)[len(model_input):].strip()","metadata":{"trusted":true,"id":"f578abb8-75dd-4921-b533-2d887093a975"},"outputs":[],"execution_count":null},{"id":"6dfd3f3c-cc64-4863-b0fc-54fb8a740916","cell_type":"code","source":"model_4_result = sub_df.copy()","metadata":{"trusted":true,"id":"6dfd3f3c-cc64-4863-b0fc-54fb8a740916"},"outputs":[],"execution_count":null},{"id":"f14138ad-11e2-4898-a1b9-f622f9fa14ec","cell_type":"code","source":"model_path = \"MaralGPT/Maral-7B-alpha-1\"\ntokenizer_maral_7b = AutoTokenizer.from_pretrained(model_path)\nmodel_maral_7b = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true,"id":"f14138ad-11e2-4898-a1b9-f622f9fa14ec"},"outputs":[],"execution_count":null},{"id":"f9b0df87-0d11-4e72-9132-1bc7e053cf0b","cell_type":"code","source":"generate_result(model_4_result, maral_run, tokenizer_maral_7b, model_maral_7b)","metadata":{"trusted":true,"id":"f9b0df87-0d11-4e72-9132-1bc7e053cf0b"},"outputs":[],"execution_count":null},{"id":"16728673-a852-4bac-a8cc-89f53bf4534b","cell_type":"code","source":"model_4_result.to_csv('/kaggle/working/maral_7b.csv')\nmodel_4_result.head(20)","metadata":{"trusted":true,"id":"16728673-a852-4bac-a8cc-89f53bf4534b"},"outputs":[],"execution_count":null},{"id":"db19d49a-997c-41b6-9dcd-1053e0991ad6","cell_type":"code","source":"del maral_run\ndel tokenizer_maral_7b\ndel model_maral_7b\ncleanup()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fcfa590e-3f23-40e6-85bf-523d68b3c4b4","cell_type":"markdown","source":"### MehdiHosseiniMoghadam/AVA-Llama-3-V2","metadata":{"id":"fcfa590e-3f23-40e6-85bf-523d68b3c4b4"}},{"id":"f90b392e-2b2c-441e-be19-b261a55c9a3f","cell_type":"code","source":"def remove_brackets_content(text):\n    text = re.sub(r'\\s*\\([^)]*\\)', '', text)\n    return text.rstrip('\\n')\n\ndef ava_run(prompt, tokenizer, model):\n    TEMPLATE = \"### Human:{context}\\n ###{prompt}\"\n    CONTEXT = prompt[0]['content']\n    PROMPT = remove_brackets_content(prompt[1]['content'])\n\n    model_input = TEMPLATE.format(context=CONTEXT, prompt=PROMPT)\n    inputs = tokenizer(model_input, return_tensors=\"pt\").to(model.device)\n\n    generation_config = GenerationConfig(\n        do_sample=False,\n        max_new_tokens=5,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    outputs = model.generate(**inputs, generation_config=generation_config)\n    outputs = tokenizer.decode(outputs[0], skip_special_tokens=True)[len(model_input):].strip().split('\\n')[0]\n    return outputs","metadata":{"trusted":true,"id":"f90b392e-2b2c-441e-be19-b261a55c9a3f"},"outputs":[],"execution_count":null},{"id":"aed05872-3fa5-4bed-9d26-e720f7f8d799","cell_type":"code","source":"model_5_result = sub_df.copy()","metadata":{"trusted":true,"id":"aed05872-3fa5-4bed-9d26-e720f7f8d799"},"outputs":[],"execution_count":null},{"id":"9bd6638c-3ee2-4ab5-b42f-041fda00801a","cell_type":"code","source":"model_path = \"MehdiHosseiniMoghadam/AVA-Llama-3-V2\"\ntokenizer_ava_8b = AutoTokenizer.from_pretrained(model_path)\nmodel_ava_8b = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true,"id":"9bd6638c-3ee2-4ab5-b42f-041fda00801a"},"outputs":[],"execution_count":null},{"id":"c5869e31-9b07-4d97-ba54-14fc8fb0e39b","cell_type":"code","source":"generate_result(model_5_result, ava_run, tokenizer_ava_8b, model_ava_8b)","metadata":{"trusted":true,"id":"c5869e31-9b07-4d97-ba54-14fc8fb0e39b"},"outputs":[],"execution_count":null},{"id":"9d29d39f-b4ad-43df-b763-f1d8213316d8","cell_type":"code","source":"model_5_result.to_csv('/kaggle/working/ava_8b.csv')\nmodel_5_result.head(20)","metadata":{"trusted":true,"id":"9d29d39f-b4ad-43df-b763-f1d8213316d8"},"outputs":[],"execution_count":null},{"id":"8c35509a-2d58-4862-a359-83c64cf69b2e","cell_type":"code","source":"del ava_run\ndel tokenizer_ava_8b\ndel model_ava_8b\ncleanup()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dbe0c789-3a42-41ca-a120-f59f61836b88","cell_type":"markdown","source":"### ViraIntelligentDataMining/PersianLLaMA-13B-Instruct","metadata":{"id":"dbe0c789-3a42-41ca-a120-f59f61836b88"}},{"id":"f1290710-507a-4fb1-a363-ead3faa6dfd6","cell_type":"code","source":"def remove_brackets_content(text):\n    text = re.sub(r'\\s*\\([^)]*\\)', '', text)\n    return text.rstrip('\\n')\n\ndef persian_llama_run(prompt, tokenizer, model):\n    TEMPLATE = \"### Instruction:{context}{prompt}\"\n    CONTEXT = prompt[0]['content']\n    PROMPT = remove_brackets_content(prompt[1]['content'])\n\n    model_input = TEMPLATE.format(context=CONTEXT, prompt=PROMPT)\n    inputs = tokenizer(model_input, return_tensors=\"pt\").to(model.device)\n\n    generation_config = GenerationConfig(\n        do_sample=False,\n        max_new_tokens=5,\n        pad_token_id=tokenizer.eos_token_id,\n        eos_token_id=tokenizer.eos_token_id,\n    )\n\n    outputs = model.generate(**inputs, generation_config=generation_config)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)[len(model_input):].strip()","metadata":{"trusted":true,"id":"f1290710-507a-4fb1-a363-ead3faa6dfd6"},"outputs":[],"execution_count":null},{"id":"fc8260c6-71c6-4bb0-b1bd-ef8e84671630","cell_type":"code","source":"model_6_result = sub_df.copy()","metadata":{"trusted":true,"id":"fc8260c6-71c6-4bb0-b1bd-ef8e84671630"},"outputs":[],"execution_count":null},{"id":"08073005-f6c7-445a-bf82-2643440ff305","cell_type":"code","source":"model_path = \"ViraIntelligentDataMining/PersianLLaMA-13B-Instruct\"\ntokenizer_persian_llama_13b = LlamaTokenizer.from_pretrained(model_path)\nmodel_persian_llama_13b = LlamaForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"trusted":true,"id":"08073005-f6c7-445a-bf82-2643440ff305"},"outputs":[],"execution_count":null},{"id":"1656a1a3-e83f-4071-b8a9-ec83729867ee","cell_type":"code","source":"generate_result(model_6_result, persian_llama_run, tokenizer_persian_llama_13b, model_persian_llama_13b)","metadata":{"trusted":true,"id":"1656a1a3-e83f-4071-b8a9-ec83729867ee"},"outputs":[],"execution_count":null},{"id":"a0ee5cac-fce9-48ad-a7d5-cbad5b48c0ac","cell_type":"code","source":"model_6_result.to_csv('/kaggle/working/persian_llama_13b.csv')\nmodel_6_result.head(20)","metadata":{"trusted":true,"id":"a0ee5cac-fce9-48ad-a7d5-cbad5b48c0ac"},"outputs":[],"execution_count":null},{"id":"cb355ead-57d4-496c-a768-d6ae8c6d7903","cell_type":"code","source":"del persian_llama_run\ndel tokenizer_persian_llama_13b\ndel model_persian_llama_13b\ncleanup()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"387d6840-5755-4cb9-8282-0de9d660da84","cell_type":"markdown","source":"## Result","metadata":{"id":"387d6840-5755-4cb9-8282-0de9d660da84"}},{"id":"fba8e916-46a5-410b-b469-ca578bcb81c3","cell_type":"code","source":"# model_1_result = pd.read_csv('/kaggle/input/result-sub/part_dorna_8b.csv', index_col=[0])\n# model_2_result = pd.read_csv('/kaggle/input/result-sub/ut_mind_7b.csv', index_col=[0])\n# model_3_result = pd.read_csv('/kaggle/input/result-sub/cohere_aya_8b.csv', index_col=[0])\n# model_4_result = pd.read_csv('/kaggle/input/result-sub/maral_7b.csv', index_col=[0])\n# model_5_result = pd.read_csv('/kaggle/input/result-sub/ava_8b.csv', index_col=[0])\n# model_6_result = pd.read_csv('/kaggle/input/result-sub/persian_llama_13b.csv', index_col=[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d784bc19-4630-4ab4-82d9-1b1bc914b1b5","cell_type":"code","source":"def map_sentiment(df):\n    def standardize_value(value):\n        if value.upper() in label_en_fa:\n            return value\n        elif value in label_fa_en:\n            return label_fa_en[value]\n        else:\n            return \"-\"\n\n    experiment_keys = list(prompts.keys())\n    for exp in experiment_keys:\n        df[exp] = df[exp].apply(standardize_value)","metadata":{"trusted":true,"id":"d784bc19-4630-4ab4-82d9-1b1bc914b1b5"},"outputs":[],"execution_count":null},{"id":"c2bc760b-d7c8-4801-afd0-b2fdb63e1afd","cell_type":"code","source":"def plot_confusion_matrix(df):\n    labels = ['POSITIVE', 'NEGATIVE', 'NEUTRAL', 'OTHER']\n    prediction_columns = list(prompts.keys())\n\n    num_preds = len(prediction_columns)\n    cols = 2\n    rows = (num_preds + 1) // cols\n\n    fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 5 * rows))\n    axes = axes.flatten()\n\n    for i, pred_col in enumerate(prediction_columns):\n        cm = confusion_matrix(df['sentiment'], df[pred_col], labels=labels)\n        cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n\n        sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', ax=axes[i], cbar=False)\n        axes[i].set_title(f'Confusion Matrix: {pred_col}')\n        axes[i].set_xlabel('Predicted')\n        axes[i].set_ylabel('True')\n\n    for j in range(i + 1, len(axes)):\n        fig.delaxes(axes[j])\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"id":"c2bc760b-d7c8-4801-afd0-b2fdb63e1afd"},"outputs":[],"execution_count":null},{"id":"08161cf7-1e8a-4607-b532-0c989da47d51","cell_type":"code","source":"def calculate_metrics(df):\n    labels = ['POSITIVE', 'NEGATIVE', 'NEUTRAL', 'OTHER']\n    prediction_columns = list(prompts.keys())\n\n    results = {}\n\n    for i, pred_col in enumerate(prediction_columns):\n        report = classification_report(df['sentiment'], df[pred_col], labels=labels, output_dict=True, zero_division=0)\n\n        report[\"accuracy\"] = {\n            \"precision\": accuracy_score(df['sentiment'], df[pred_col]),\n            \"recall\": accuracy_score(df['sentiment'], df[pred_col]),\n            \"f1-score\": accuracy_score(df['sentiment'], df[pred_col]),\n            \"support\": len(df['sentiment'])\n        }\n\n        report_df = pd.DataFrame(report).transpose()\n        report_df = report_df.round(3)\n        results[pred_col] = report_df\n\n    return results","metadata":{"trusted":true,"id":"08161cf7-1e8a-4607-b532-0c989da47d51"},"outputs":[],"execution_count":null},{"id":"419678ad-de6b-4915-a0a9-81c2a5516dfb","cell_type":"code","source":"def show_metrics_grid(df):\n    metrics_dict = calculate_metrics(df)\n    dfs = list(metrics_dict.values())\n    titles = list(metrics_dict.keys())\n\n    html_tables = [\n        f\"<div style='padding:10px'><h4 style='text-align:center'>Experiment: {title}</h4>{df.to_html()}</div>\"\n        for title, df in zip(titles, dfs)\n    ]\n\n    rows = [''.join(html_tables[::2]), ''.join(html_tables[1::2])]\n\n    grid_html = '<table><tr><td>' + '</td><td>'.join(rows) + '</td></tr></table>'\n    display_html(grid_html, raw=True)","metadata":{"trusted":true,"id":"419678ad-de6b-4915-a0a9-81c2a5516dfb"},"outputs":[],"execution_count":null},{"id":"c9ec26f9-c718-4a1f-bbda-be69d9407071","cell_type":"markdown","source":"### PartAI/Dorna2-Llama3.1-8B-Instruct","metadata":{"id":"c9ec26f9-c718-4a1f-bbda-be69d9407071"}},{"id":"58643cb7-59d4-427c-8e5e-185a9cc09ddf","cell_type":"code","source":"map_sentiment(model_1_result)","metadata":{"trusted":true,"id":"58643cb7-59d4-427c-8e5e-185a9cc09ddf"},"outputs":[],"execution_count":null},{"id":"e1ff48c1-3d08-4316-956e-cfc68d81c411","cell_type":"code","source":"plot_confusion_matrix(model_1_result)","metadata":{"trusted":true,"id":"e1ff48c1-3d08-4316-956e-cfc68d81c411"},"outputs":[],"execution_count":null},{"id":"0791e053-5fd2-4484-9bdd-cc8e55b9f405","cell_type":"code","source":"show_metrics_grid(model_1_result)","metadata":{"trusted":true,"id":"0791e053-5fd2-4484-9bdd-cc8e55b9f405"},"outputs":[],"execution_count":null},{"id":"753b50a9-0763-4005-b86a-89e7d0764243","cell_type":"markdown","source":"### universitytehran/PersianMind-v1.0","metadata":{"id":"753b50a9-0763-4005-b86a-89e7d0764243"}},{"id":"be360dac-8e4a-4539-84cc-503b4e729230","cell_type":"code","source":"map_sentiment(model_2_result)","metadata":{"trusted":true,"id":"be360dac-8e4a-4539-84cc-503b4e729230"},"outputs":[],"execution_count":null},{"id":"433d1aff-eeaf-46f2-9f12-eb200bcc8c0e","cell_type":"code","source":"plot_confusion_matrix(model_2_result)","metadata":{"trusted":true,"id":"433d1aff-eeaf-46f2-9f12-eb200bcc8c0e"},"outputs":[],"execution_count":null},{"id":"43a56566-7593-4590-be69-d08d607433b4","cell_type":"code","source":"show_metrics_grid(model_2_result)","metadata":{"trusted":true,"id":"43a56566-7593-4590-be69-d08d607433b4"},"outputs":[],"execution_count":null},{"id":"9429ffe3-b803-485c-ad0b-429b73dde59e","cell_type":"markdown","source":"### CohereLabs/aya-expanse-8b","metadata":{"id":"9429ffe3-b803-485c-ad0b-429b73dde59e"}},{"id":"e9894c83-9cc6-4b8e-aab7-883785ee5563","cell_type":"code","source":"map_sentiment(model_3_result)","metadata":{"trusted":true,"id":"e9894c83-9cc6-4b8e-aab7-883785ee5563"},"outputs":[],"execution_count":null},{"id":"7681119b-d907-4a68-b622-b91cfb77e6f8","cell_type":"code","source":"plot_confusion_matrix(model_3_result)","metadata":{"trusted":true,"id":"7681119b-d907-4a68-b622-b91cfb77e6f8"},"outputs":[],"execution_count":null},{"id":"52be328f-818a-4304-b37e-79acdaba14f7","cell_type":"code","source":"show_metrics_grid(model_3_result)","metadata":{"trusted":true,"id":"52be328f-818a-4304-b37e-79acdaba14f7"},"outputs":[],"execution_count":null},{"id":"4b372be0-b775-4ff3-8da2-b732055ed918","cell_type":"markdown","source":"### MaralGPT/Maral-7B-alpha-1","metadata":{"id":"4b372be0-b775-4ff3-8da2-b732055ed918"}},{"id":"84dc0280-e1fd-44a0-aa5f-01e75c68d1cc","cell_type":"code","source":"map_sentiment(model_4_result)","metadata":{"trusted":true,"id":"84dc0280-e1fd-44a0-aa5f-01e75c68d1cc"},"outputs":[],"execution_count":null},{"id":"c906f1b9-0848-4db7-bb5e-a745f1a7a428","cell_type":"code","source":"plot_confusion_matrix(model_4_result)","metadata":{"trusted":true,"id":"c906f1b9-0848-4db7-bb5e-a745f1a7a428"},"outputs":[],"execution_count":null},{"id":"52ab4a4a-52fd-44e9-9e30-c9f9ad374ddb","cell_type":"code","source":"show_metrics_grid(model_4_result)","metadata":{"trusted":true,"id":"52ab4a4a-52fd-44e9-9e30-c9f9ad374ddb"},"outputs":[],"execution_count":null},{"id":"d0905b81-c852-4f0d-ac42-54d8c38a5376","cell_type":"markdown","source":"### MehdiHosseiniMoghadam/AVA-Llama-3-V2","metadata":{"id":"d0905b81-c852-4f0d-ac42-54d8c38a5376"}},{"id":"b1e04247-695a-4ed6-ab07-0d5f6d37da03","cell_type":"code","source":"map_sentiment(model_5_result)","metadata":{"trusted":true,"id":"b1e04247-695a-4ed6-ab07-0d5f6d37da03"},"outputs":[],"execution_count":null},{"id":"f8d03960-55ec-42e5-b69e-5730aaee02fd","cell_type":"code","source":"plot_confusion_matrix(model_5_result)","metadata":{"trusted":true,"id":"f8d03960-55ec-42e5-b69e-5730aaee02fd"},"outputs":[],"execution_count":null},{"id":"b2b065ba-a5e3-421f-a6a1-dcbe2147e2f2","cell_type":"code","source":"show_metrics_grid(model_5_result)","metadata":{"trusted":true,"id":"b2b065ba-a5e3-421f-a6a1-dcbe2147e2f2"},"outputs":[],"execution_count":null},{"id":"768d7a6c-cb48-4a58-bb31-a1024e8cf35e","cell_type":"markdown","source":"### ViraIntelligentDataMining/PersianLLaMA-13B-Instruct","metadata":{"id":"768d7a6c-cb48-4a58-bb31-a1024e8cf35e"}},{"id":"f19fb451-69ac-4a6a-98fd-7fadbd67f6c8","cell_type":"code","source":"map_sentiment(model_6_result)","metadata":{"trusted":true,"id":"f19fb451-69ac-4a6a-98fd-7fadbd67f6c8"},"outputs":[],"execution_count":null},{"id":"02eb6b60-5283-451d-93a8-5a1e2ef9ba88","cell_type":"code","source":"plot_confusion_matrix(model_6_result)","metadata":{"trusted":true,"id":"02eb6b60-5283-451d-93a8-5a1e2ef9ba88"},"outputs":[],"execution_count":null},{"id":"853d1be8-7de3-4ffd-bc76-56c623e031d7","cell_type":"code","source":"show_metrics_grid(model_6_result)","metadata":{"trusted":true,"id":"853d1be8-7de3-4ffd-bc76-56c623e031d7"},"outputs":[],"execution_count":null},{"id":"6b73f6bd-df14-4644-9b72-b5b9f3fbc398","cell_type":"markdown","source":"## Conclusion","metadata":{"id":"6b73f6bd-df14-4644-9b72-b5b9f3fbc398"}},{"id":"406d7a87-5fc5-48f1-bf2a-a7f426aaac00","cell_type":"code","source":"def get_best_experiment(metrics):\n    result = {}\n    for k, v in metrics.items():\n        best_accuracy = 0\n        best = None\n        key = \"\"\n        for _, experiment in v.items():\n            if experiment.loc['weighted avg']['f1-score'] > best_accuracy:\n                best = experiment\n                best_accuracy = experiment.loc['weighted avg']['f1-score']\n                key = _\n        result[k+'-'+key] = {}\n        result[k+'-'+key]['best'] = best\n    return result","metadata":{"trusted":true,"id":"406d7a87-5fc5-48f1-bf2a-a7f426aaac00"},"outputs":[],"execution_count":null},{"id":"5e104018-7250-4e90-98f9-b4a5229f0b44","cell_type":"code","source":"metrics = {\n    \"PartAI/Dorna2-Llama3.1-8B-Instruct\": calculate_metrics(model_1_result),\n    \"universitytehran/PersianMind-v1.0\": calculate_metrics(model_2_result),\n    \"CohereLabs/aya-expanse-8b\": calculate_metrics(model_3_result),\n    \"MaralGPT/Maral-7B-alpha-1\": calculate_metrics(model_4_result),\n    \"MehdiHosseiniMoghadam/AVA-Llama-3-V2\": calculate_metrics(model_5_result),\n    \"ViraIntelligentDataMining/PersianLLaMA-13B-Instruct\": calculate_metrics(model_6_result)\n}","metadata":{"trusted":true,"id":"5e104018-7250-4e90-98f9-b4a5229f0b44"},"outputs":[],"execution_count":null},{"id":"05ad6c0d-0a4f-4d68-81dd-d9d0713832e0","cell_type":"code","source":"best_for_each_model = get_best_experiment(metrics)","metadata":{"trusted":true,"id":"05ad6c0d-0a4f-4d68-81dd-d9d0713832e0"},"outputs":[],"execution_count":null},{"id":"974a5f74-6f4a-49f8-aeb3-191fe564c991","cell_type":"markdown","source":"### Radar Chart","metadata":{"id":"974a5f74-6f4a-49f8-aeb3-191fe564c991"}},{"id":"6ef6fb74-6f5b-4266-a71d-15d755183c1c","cell_type":"code","source":"def plot_radar_chart(data, title, key, ax):\n    metrics = ['POSITIVE',\n               'NEGATIVE',\n               'NEUTRAL',\n               'OTHER',\n               'macro avg',\n               'weighted avg',\n               'accuracy']\n\n    N = len(metrics)\n    theta = np.linspace(0, 2 * np.pi, N, endpoint=False)\n    theta = np.concatenate([theta, [theta[0]]])\n\n    ax.plot(subplot_kw={'projection': 'polar'})\n\n    ax.set_title(title, y=1.15, fontsize=20)\n    ax.set_theta_zero_location(\"N\")\n    ax.set_theta_direction(-1)\n    ax.set_rlabel_position(90)\n    ax.spines['polar'].set_zorder(1)\n    ax.spines['polar'].set_color('lightgrey')\n\n    color_palette = [\n        '#FF0000',\n        '#0000FF',\n        '#FFD700',\n        '#FF8C00',\n        '#008000',\n        '#9467bd']\n\n    idx = 0\n\n    for model_name, metric in data.items():\n        experiment = metric[key]\n        values = experiment.loc[metrics]['f1-score'].to_list()\n        values = values + [values[0]]\n        ax.plot(theta, values, linewidth=1.75, linestyle='solid', label=model_name, marker='o', markersize=10, color=color_palette[idx % len(color_palette)])\n        #ax.fill(theta, values, alpha=0.50, color=color_palette[idx % len(color_palette)])\n        idx+=1\n\n    ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n    ax.set_yticklabels([\"0\", \"20\", \"40\", \"60\", \"80\", \"100\"], color=\"black\", size=12)\n\n    ax.set_xticks(theta)\n    ax.set_xticklabels(metrics+[metrics[0]], color='black', size=12)\n    return fig","metadata":{"trusted":true,"id":"6ef6fb74-6f5b-4266-a71d-15d755183c1c"},"outputs":[],"execution_count":null},{"id":"f1e817d8-30aa-4b97-934f-26443839ebd5","cell_type":"markdown","source":"### All Experiments","metadata":{"id":"f1e817d8-30aa-4b97-934f-26443839ebd5"}},{"id":"d030ffbc-38e7-44f6-a05c-d1f64ea07b2b","cell_type":"code","source":"keys = list(prompts.keys())\n\nnum_charts = len(keys)\ncols = 2\nrows = math.ceil(num_charts / cols)\n\nfig, axs = plt.subplots(rows, cols, subplot_kw=dict(polar=True), figsize=(12, 5 * rows))\n\naxs = axs.reshape(rows, cols) if rows > 1 else [axs]\n\nfor idx, key in enumerate(keys):\n    row, col = divmod(idx, cols)\n    ax = axs[row][col]\n    plot_radar_chart(metrics, f\"Experiment: {key}\", key, ax)\n\nfor idx in range(len(keys), rows * cols):\n    row, col = divmod(idx, cols)\n    fig.delaxes(axs[row][col])\n\nhandles, labels = axs[0][0].get_legend_handles_labels()\n\nfig.legend(\n    handles,\n    labels,\n    loc='upper center',\n    bbox_to_anchor=(0.5, -0.01),\n    fontsize=12,\n    frameon=False\n)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"id":"d030ffbc-38e7-44f6-a05c-d1f64ea07b2b"},"outputs":[],"execution_count":null},{"id":"91c0d1a2-e936-43fa-b778-0048066256f3","cell_type":"markdown","source":"## Best Model","metadata":{"id":"91c0d1a2-e936-43fa-b778-0048066256f3"}},{"id":"f7057771-4a91-42fc-b37c-5c6a5190fb11","cell_type":"code","source":"fig, ax = plt.subplots(subplot_kw=dict(polar=True), figsize=(6, 6))\nplot_radar_chart(best_for_each_model, \"Experiment: Best Model\", 'best' ,ax)\nax.legend(loc='upper right', bbox_to_anchor=(2.1, 1.1))\nplt.show()","metadata":{"trusted":true,"id":"f7057771-4a91-42fc-b37c-5c6a5190fb11"},"outputs":[],"execution_count":null}]}